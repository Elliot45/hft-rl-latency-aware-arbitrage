# Latency-Aware HFT Arbitrage with Deep Reinforcement Learning

Projet de recherche explorant l'utilisation du Deep Reinforcement Learning pour concevoir une stratÃ©gie d'arbitrage statistique haute frÃ©quence (HFT), en tenant compte de la latence d'exÃ©cution dans un environnement de marchÃ© simulÃ©.

---

## ğŸ” Objectifs

- ğŸ“Š Simuler un environnement de marchÃ© rÃ©aliste avec latence, spread, et carnet d'ordres simplifiÃ©
- ğŸ§  EntraÃ®ner un agent PPO via `Stable-Baselines3` pour dÃ©tecter des opportunitÃ©s dâ€™arbitrage
- âš”ï¸ Comparer les performances Ã  des stratÃ©gies naÃ¯ves (Random, Buy & Hold)
- ğŸ“ˆ Visualiser la reward, lâ€™Ã©volution du P&L et les dÃ©cisions de lâ€™agent
- ğŸ”„ PrÃ©parer le terrain pour un passage Ã  des donnÃ©es rÃ©elles et des agents plus complexes

---

## Structure du projet

```
hft-rl-latency-aware-arbitrage/
â”œâ”€â”€ src/                    # Code source
â”‚   â”œâ”€â”€ environment.py      # Gymnasium.Env simulÃ© avec latence
â”‚   â”œâ”€â”€ trainer.py          # EntraÃ®nement PPO
â”‚   â”œâ”€â”€ evaluate.py         # Ã‰valuation et comparaison
â”‚   â”œâ”€â”€ baselines.py        # StratÃ©gies naÃ¯ves
â”‚   â””â”€â”€ models/             # (optionnel) agents custom
â”œâ”€â”€ notebooks/              # Explorations et visualisations
â”‚   â”œâ”€â”€ ppo_training.ipynb
â”‚   â””â”€â”€ evaluate_agent.ipynb
â”œâ”€â”€ results/                # Checkpoints et figures
â”œâ”€â”€ tests/                  # Tests unitaires (env)
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.py
```

---

## Lancement rapide

1. **Installer les dÃ©pendances** :

```bash
pip install -r requirements.txt
```

2. **EntraÃ®ner un agent PPO** :

```bash
python -m src.trainer
```

3. **Ã‰valuer et comparer aux baselines** :

```bash
python -m src.evaluate
```

---

## Exemple de sortie

- Reward cumulÃ©e sur 500 steps
- P&L final (cash + inventaire Ã— prix)
- Comparaison PPO vs Random vs Buy & Hold

*Figure gÃ©nÃ©rÃ©e automatiquement dans `evaluate.py`.*

---

## AmÃ©liorations prÃ©vues

- [ ] Ajout de donnÃ©es rÃ©elles (Binance, LOBSTER, etc.)
- [ ] Environnement multi-actifs ou multi-niveaux
- [ ] Agent avec mÃ©moire (LSTM, Transformer)
- [ ] Logging avancÃ© (TensorBoard, MLflow)
- [ ] Backtest + mÃ©triques rÃ©alistes (Sharpe, Drawdown)

---

## Auteur

Projet initiÃ© par **Elliot Piet**, dans le cadre d'une recherche appliquÃ©e en trading algorithmique.

---

## Licence

MIT License
